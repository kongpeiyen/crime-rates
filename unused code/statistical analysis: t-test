#assumptions for t-test

https://ncss-wpengine.netdna-ssl.com/wp-content/themes/ncss/pdf/Procedures/NCSS/Two-Sample_T-Test.pdf 
Two-Sample T-Test Assumptions
The assumptions of the two-sample t-test are:
1. The data are continuous (not discrete).

2. The data follow the normal probability distribution.

3. The variances of the two populations are equal. (If not, the Aspin-Welch Unequal-Variance test is used.)
https://www.itl.nist.gov/div898/handbook/eda/section3/eda359.htm
An F-test (Snedecor and Cochran, 1983) is used to test if the variances of two populations are equal. 
This test can be a two-tailed test or a one-tailed test. The two-tailed version tests against the alternative that the variances are not equal. 
The one-tailed version only tests in one direction, that is the variance from the first population is either greater than or less than (but not both) the second population variance. 
The choice is determined by the problem. For example, if we are testing a new process, we may only be interested in knowing if the new process is less variable than the old process.

4. The two samples are independent. There is no relationship between the individuals in one sample as compared to the other (as there is in the paired t-test).
use chi-square test to find out if its independent 
The formula for calculating the Chi-square statistic (X²) is shown as follows:
X² = sum of [(observed-expected)² / expected]

5. Both samples are simple random samples from their respective populations. Each individual in the population has an equal probability of being selected in the sample.

For our project: 
1. Yes it is 
2. (still trying to test) 
3. (still trying to test) 
4. 
5. 



1. continous 


2. testing if our data shows normal probability distirbution 
import pandas as pd
burglary = pd.read_csv('databurglary.csv')
burglary.head()
#for histogram
burglary.hist()

3. testing if the varainces are equal 
https://stackoverflow.com/questions/21494141/how-do-i-do-a-f-test-in-python 

#have not changed the values yet
a = [1,2,1,2,1,2,1,2,1,2]
b = [1,3,-1,2,1,5,-1,6,-1,2]
print('Variance a={0:.3f}, Variance b={1:.3f}'.format(np.var(a, ddof=1), np.var(b, ddof=1)))
fstatistics = np.var(a, ddof=1)/np.var(b, ddof=1) # because we estimate mean from data
fdistribution = stats.f(len(a)-1,len(b)-1) # build an F-distribution object
p_value = 2*min(fdistribution.cdf(f_critical), 1-fdistribution.cdf(f_critical))
f_critical1 = fdistribution.ppf(0.025)
f_critical2 = fdistribution.ppf(0.975)
print(fstatistics,f_critical1, f_critical2 )
if (p_value<0.05):
    print('Reject H0', p_value)
else:
    print('Cant Reject H0', p_value)

4. 
https://machinelearningmastery.com/chi-squared-test-for-machine-learning/

#use chi-squared to test for independence 

# chi-squared test with similar proportions
from scipy.stats import chi2_contingency
from scipy.stats import chi2

# contingency table (we probably have to change it, but im not sure what to change it to)
table = [	[10, 20, 30],
			[6,  9,  17]]
print(table)
stat, p, dof, expected = chi2_contingency(table)
print('dof=%d' % dof)
print(expected)



#Import necessary libraries
from scipy.stats import ttest_ind
import numpy as np
import pandas as pd

#Print real data 2020 to later write it as an array
sales_data.tail(11)

#Print predicted 2020 data to later write as an array
prediction = pd.DataFrame(arima_model.predict(n_periods = 11),index=test.index)
prediction.columns = ['predicted_burglaries']
prediction

#Write 2020 data as arrays
real_burglaries_2020 = [5431,5286,5241,4705,3819,2517,2946,3321,3808,3951, 4015]
predicted_burglaries_2020 = [4977,5195,5142,5194,4891,5079,4991,5039,5366,5855, 6010]

#Perform t-test and test hypothesis
ttest,pval = ttest_ind(real_burglaries_2020,predicted_burglaries_2020)
print("p-value",pval)
if pval <0.05:
  print("we reject null hypothesis")
else:
  print("we accept null hypothesis")




