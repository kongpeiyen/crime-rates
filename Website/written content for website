A]INTRODUCTION PAGE 

1) content and motivation 
-> see proposal and presentation notes 

2) aims and relevance of project
-> see proposal notes 

3) explanation of all the variables, city and timeframe 
-> see proposal and presentation notes 
-> see research 
-> google drive

-section on biographies
-hypothesis

Burglaries 
Null Hypothesis 1: we hypothesize that the number of residential burglaries decreased after the outbreak of Covid-19
Alternate Hypothesis 1: we hypothesize that the number of residential burglaries did not change after the outbreak of Covid-19

Null Hypothesis 2:  we hypothesize that the number of commercial burglaries increased after the outbreak of Covid-19
Alternate Hypothesis 2: we hypothesize that the number of commercial burglaries did not change after the outbreak of Covid-19


Sexual assaults 
Null Hypothesis 3: we hypothesize that the number of sexual assaults changed after the outbreak of Covid-19
Alternate Hypothesis 3: we hypothesize that the number of sexual assaults did not change after the outbreak of Covid-19


Drug offences 
Null Hypothesis 4: we hypothesize that the number of drug offences changed after the outbreak of Covid-19
Alternate Hypothesis 4: we hypothesize that the number of drug offences did not change after the outbreak of Covid-19




-presentation of data visualisations

B] DATA COLLECTION 

1) sources of data 
-explain how he data was collected 
-limitations of having just one data source

2) cleaning the data
->explain the steps of cleaning the data 
->difficulties cleaning the data 
->use for cleaned data 

C]DATA VISUALISATIONS AND ANALYSIS 

1) scatter plots 
-motivation in doing scatterplots and what they bring to the project
-explain how they were done and link to github gist 
-limitations 

2)cloropleth map
-explain how the map works
-explain motivations and what the map brings to the project 
-code gists
-explain the worflow in mking the map: difficulties and explanation of changing map type 
-limitations

3) ARIMA predictive model
-explain motivation in choosing model
-explain aims of model and what it brings to project 
-explain coding process and process of putting the cleaned data inside 
-interpret the results 
-explain the accuracy
-limitations 


D] CONCLUSION 
-answering the research question 
-interpreting data analsysis findings 
-how does this resaerch fit into the wider context and what can still be done in future research 





*Cleaning of the data for the predictive model*

In building the ARIMA predictive model and [insert name of last visualisation] one of the main challenges and consequential components of the code was the section on data cleaning. 

The two datasets we were working with, downloaded from the metropolitan police website were indeed not in the right format for importing into our code. To make our visualisations the most reproducible we wrote a code to ‘clean our data’. 
We had four main goals in re-formatting our raw datasets: 
We have two data sets: one for the last 24 months, and one that starts in 2008 and ends where the first one starts and we needed to combine them  into one dataframe: 
>INSERT RELEVANT CODE GIST
We were able to do this by...

The data set downloaded from the Met Police website had many crimes but our research project is limited to the six following offences: ‘Burglary - Business and Community’, ‘Burglary - Residential’, ‘Drug Trafficking’, ‘Possession of Drugs’, ‘Rape’ and ‘Other Sexual Offenses’. Hence we needed our code to get rid of of all the other crimes. 
 >INSERT RELEVANT CODE GIST
We were able to do this by...

Our datasets were defined geographically by borough in London. This was an issue for the visualisations we wished to make because we needed the dataset to show the respective crimes according to time, more specifically  according to months. Thus, our aim was to rid ourselves of the geographic variable by summing up the crimes in all boroughs for a given month. The result would be a table of crimes committed in London for each month between 2008 and 2020..
 >INSERT RELEVANT CODE GIST
We were able to do this by...

Finally, we needed to change the names of the crimes in one of our data sets so that when we combine the two, the crimes, which are the same, would have the same appellation. For example, ‘Burglary- Residential’ was called ‘Burglary in Dwellings’ in one data set and we changed it to ‘Burglary-Residential’ to assure the consistency of our data. 
  >INSERT RELEVANT CODE GIST
We were able to do this by...










#research on interpreting data anaslyis 

ARIMA MODEL

-> interpreting the accuracy:
https://stats.stackexchange.com/questions/194453/interpreting-accuracy-results-for-an-arima-model-fit

Out of all the one simplest to understand is MAPE (Mean absolute percentage error). It considers actual values fed into model and fitted values from the model and calculates absolute difference between the two as a percentage of actual value and finally calculates mean of that.
https://towardsdatascience.com/machine-learning-part-19-time-series-and-autoregressive-integrated-moving-average-model-arima-c1005347b0d7
